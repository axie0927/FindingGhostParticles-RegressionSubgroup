{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f26b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529d58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't know if we can use the GPUs on DSMLP to utilize the CUDA function of Pytorch\n",
    "# So do not set epoch too high in order to have a faster training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7262bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create varaibles that holds a dataframe\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd, \"Data/\")\n",
    "data_files = [f for f in os.listdir(str(data_dir)) if f.endswith('csv')]\n",
    "\n",
    "data_train_name = [f for f in data_files if 'TRAIN' in f]\n",
    "data_test_name = [f for f in data_files if 'TEST' in f]\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(data_dir,data_train_name[0]))\n",
    "test_df = pd.read_csv(os.path.join(data_dir,data_test_name[0]))\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "\n",
    "# feature selection and renaming\n",
    "\n",
    "def manipulate_cols(df):\n",
    "    boolean_col = ['highavse','lowavse','truedcr','lq']\n",
    "    useless_col = ['tdrift50','tdrift10']\n",
    "    new_df = df.drop(columns=boolean_col+['id']+useless_col)\n",
    "    new_df.columns = [col.strip().replace(' ','_') for col in new_df.columns]\n",
    "    return new_df\n",
    "\n",
    "train_df = manipulate_cols(train_df)\n",
    "test_df = manipulate_cols(test_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reshaping for consistency\n",
    "X_train = train_df.drop(columns=['energylabel']).values\n",
    "X_test = test_df.drop(columns=['energylabel']).values\n",
    "y_train = train_df['energylabel'].values.reshape(-1,1)\n",
    "y_test = test_df['energylabel'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdde438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Extremely Important: REMOVE \"pass\" and UNCOMMENT the codes below to RUN it !!!!!  #\n",
    "#####################################################################################\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# NaN Will Ruin the NN! So make sure it desn't contain any NaN in any corner!\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "features = [\n",
    "    'tdrift', 'rea', 'dcr', 'peakindex', 'peakvalue', 'tailslope',\n",
    "    'currentamp', 'lfpr', 'lq80', 'areagrowthrate', 'inflection_point',\n",
    "    'risingedgeslope'\n",
    "]\n",
    "print(train_df[features].std())\n",
    "print(\"Any NaNs in X_train?\", np.isnan(X_train).any())\n",
    "print(\"Any NaNs in X_test?\", np.isnan(X_test).any())\n",
    "print('\\n')\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678c3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler() # VERY IMPORTANT! We also need to transform it back to original after prediction!\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a55ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pytorch Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "674ab909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader\n",
    "\n",
    "class NPDL(Dataset): # Neutrino Physics Deel Learning\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "train_NPDL = NPDL(X_train_tensor,y_train_tensor)\n",
    "test_NPDL = NPDL(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_NPDL, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_NPDL, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293296b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Static int main!\n",
    "\n",
    "class SuperPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SuperPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1) \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "input_size = 12 # the number of our features\n",
    "model = SuperPredictor(input_size)\n",
    "\n",
    "accuracy = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7145d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Scaled Loss(standardization): 0.0069\n",
      "Epoch [2/20], Scaled Loss(standardization): 0.0048\n",
      "Epoch [3/20], Scaled Loss(standardization): 0.0045\n",
      "Epoch [4/20], Scaled Loss(standardization): 0.0042\n",
      "Epoch [5/20], Scaled Loss(standardization): 0.0040\n",
      "Epoch [6/20], Scaled Loss(standardization): 0.0039\n",
      "Epoch [7/20], Scaled Loss(standardization): 0.0038\n",
      "Epoch [8/20], Scaled Loss(standardization): 0.0038\n",
      "Epoch [9/20], Scaled Loss(standardization): 0.0037\n",
      "Epoch [10/20], Scaled Loss(standardization): 0.0036\n",
      "Epoch [11/20], Scaled Loss(standardization): 0.0036\n",
      "Epoch [12/20], Scaled Loss(standardization): 0.0035\n",
      "Epoch [13/20], Scaled Loss(standardization): 0.0035\n",
      "Epoch [14/20], Scaled Loss(standardization): 0.0035\n",
      "Epoch [15/20], Scaled Loss(standardization): 0.0034\n",
      "Epoch [16/20], Scaled Loss(standardization): 0.0034\n",
      "Epoch [17/20], Scaled Loss(standardization): 0.0034\n",
      "Epoch [18/20], Scaled Loss(standardization): 0.0034\n",
      "Epoch [19/20], Scaled Loss(standardization): 0.0034\n",
      "Epoch [20/20], Scaled Loss(standardization): 0.0033\n",
      "Test Loss(Scaled): 0.0037\n"
     ]
    }
   ],
   "source": [
    "# Set epoch to 100 is good, but my computer is trash, you can do it on DSMLP.\n",
    "num_epochs = 20 # Change this later according to our Computational Power!!  \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()           \n",
    "        outputs = model(X_batch)          \n",
    "        loss = accuracy(outputs, y_batch) \n",
    "        loss.backward()                 \n",
    "        optimizer.step()                \n",
    "\n",
    "        running_loss += loss.item() * X_batch.size(0)\n",
    "    epoch_loss = running_loss / len(train_NPDL)\n",
    "    #if (epoch+1) % 10 == 0:\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Scaled Loss(standardization): {epoch_loss:.4f}\")\n",
    "        \n",
    "\n",
    "model.eval()  # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    test_loss = accuracy(predictions, y_test_tensor)\n",
    "    print(f\"Test Loss(Scaled): {test_loss.item():.4f}\")\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca312f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1670.6751708984375, Average Residuals: 10.115889549255371, Variance Explained: 0.9962677320177752\n"
     ]
    }
   ],
   "source": [
    "predictions_original = scaler_y.inverse_transform(predictions.numpy())\n",
    "y_test_original = scaler_y.inverse_transform(y_test_tensor.numpy())\n",
    "\n",
    "\n",
    "MSE = mean_squared_error(y_test_original, predictions_original)\n",
    "MAE = mean_absolute_error(y_test_original, predictions_original)\n",
    "r2 = r2_score(y_test_original, predictions_original)\n",
    "\n",
    "print(f\"MSE: {MSE}, Average Residuals: {MAE}, Variance Explained: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10488fa",
   "metadata": {},
   "source": [
    "Here we can see that MSE is the lowest out of all our models, this may be our best performing model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
